{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.tensor([1,2,3])\n",
    "print('Tensor from List:',tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2 = torch.zeros(2,3)\n",
    "print(\"Tensor of zeroes:\",tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor3 = torch.rand(3,2)\n",
    "print('Random Tensor:',tensor3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_add = tensor1 + tensor2\n",
    "print(\"Additional result:\",result_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0,requires_grad=True)\n",
    "y = torch.tensor(3.0,requires_grad=True)\n",
    "\n",
    "z = x**2 + y**3\n",
    "print(\"Output tensor:\",z)\n",
    "z.backward()\n",
    "print(\"Gradient of x:\",x.grad)\n",
    "print(\"Gradient of y:\",y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = []\n",
    "number.append(10)\n",
    "number.append(20)\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "age = 17\n",
    "\n",
    "if  age >= 18:\n",
    "    results.append('Adult')\n",
    "else:\n",
    "    results.append(\"Minor\")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1,2,3,4,5,6]\n",
    "even_numbers = []\n",
    "\n",
    "for n in numbers:\n",
    "    if n % 2 == 0:\n",
    "        even_numbers.append(n)\n",
    "\n",
    "print(even_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = [85,72,90,60,40]\n",
    "remarks = []\n",
    "\n",
    "for grade in grades:\n",
    "    if grade >= 75:\n",
    "        remarks.append('Passed')\n",
    "    elif grade >= 50:\n",
    "        remarks.append('Remedial')\n",
    "    else:\n",
    "        remarks.append(\"Failed\")\n",
    "\n",
    "print(remarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0,requires_grad=True)\n",
    "y = torch.tensor(3.0,requires_grad=True)\n",
    "\n",
    "z = x**2 + y**3\n",
    "z.backward()\n",
    "\n",
    "gradients = []\n",
    "\n",
    "if x.grad > 2:\n",
    "    gradients.append(('x',x.grad.item()))\n",
    "\n",
    "if y.grad > 10:\n",
    "    gradients.append((\"y\",y.grad.item()))\n",
    "\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [95,67,82,45,73,59,88]\n",
    "remark = []\n",
    "\n",
    "for score in scores:\n",
    "    if score > 90:\n",
    "        remark.append('Excellent')\n",
    "    elif score >= 75 and score < 90:\n",
    "        remark.append(\"Good\")\n",
    "    elif score >= 60 and  score < 75:\n",
    "        remark.append('Average')\n",
    "    else:\n",
    "        remark.append('Fail')\n",
    "\n",
    "print(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([-3.0,-1.0,0.0,2.0,4.0],requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x**3\n",
    "z = y.sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gradient_signs = []\n",
    "\n",
    "for i in y:\n",
    "    if i > 0:\n",
    "        gradient_signs.append('Positive')\n",
    "    elif i == 0:\n",
    "        gradient_signs.append('Zero')\n",
    "    else:\n",
    "        gradient_signs.append('Negative')\n",
    "\n",
    "print(f\"Gradient {y} {z.backward()}\")\n",
    "print(f\"Signs {gradient_signs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([-3.0, -1.0, 0.0, 2.0, 4.0], requires_grad=True)\n",
    "\n",
    "y = x**3\n",
    "z = y.sum()\n",
    "\n",
    "z.backward()  # Compute gradients\n",
    "\n",
    "gradient_signs = []\n",
    "\n",
    "for grad in x.grad:  # Loop through gradients, not y\n",
    "    if grad > 0:\n",
    "        gradient_signs.append('Positive')\n",
    "    elif grad == 0:\n",
    "        gradient_signs.append('Zero')\n",
    "    else:\n",
    "        gradient_signs.append('Negative')\n",
    "\n",
    "print(\"Gradients:\", x.grad)\n",
    "print(\"Signs:\", gradient_signs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([-2.0,-1.0,0.0,1.0,2.0], requires_grad=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x**4 + 2*x**2\n",
    "z = y.sum()\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([-2.0,-1.0,0.0,1.0,2.0], requires_grad=True )\n",
    "\n",
    "y = x**4 + 2*x**2\n",
    "z = y.sum()\n",
    "z.backward()\n",
    "\n",
    "categories = []\n",
    "\n",
    "for grad in x.grad:\n",
    "    val = abs(grad.item())\n",
    "    if val < 5:\n",
    "        categories.append('Low')\n",
    "    elif val >= 5 and val < 20:   # âœ… correct range check\n",
    "        categories.append('Medium')\n",
    "    elif val >= 20:               # >= 20 is clearer\n",
    "        categories.append('High')\n",
    "\n",
    "print(x.grad)\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([-3.0,-1.5,0.0,1.5,3.0],requires_grad=True)\n",
    "\n",
    "y = torch.sigmoid(x) * torch.tanh(x)\n",
    "\n",
    "z = y.sum()\n",
    "z.backward()\n",
    "\n",
    "catzz = []\n",
    "\n",
    "for grad in x.grad:\n",
    "    val = abs(grad.item())\n",
    "    if val < 0.05:\n",
    "        catzz.append(\"Weak\")\n",
    "    elif val  >= 0.05  and val < 0.15:\n",
    "        catzz.append('Moderate')\n",
    "    elif val >= 0.15:\n",
    "        catzz.append(\"Strong\")\n",
    "\n",
    "print(x.grad)\n",
    "print(catzz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install imageio[ffmpeg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\francis\\AppData\\Local\\Temp\\ipykernel_16484\\2182396140.py:1: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.set_audio_backend('sox_io')\n",
      "e:\\anaconda3\\envs\\torch4\\lib\\site-packages\\torchaudio\\_internal\\module_utils.py:71: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  return func(*args, **kwargs)\n",
      "e:\\anaconda3\\envs\\torch4\\lib\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Couldn't find appropriate backend to handle uri well.wav and format None.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m torchaudio\u001b[38;5;241m.\u001b[39mset_audio_backend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msox_io\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m waveform,sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwell.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(waveform\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(sample_rate)\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\torch4\\lib\\site-packages\\torchaudio\\_backend\\utils.py:221\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[1;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m.. warning::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn 2.9, this function\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms implementation will be changed to use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchaudio.load_with_torchcodec` under the hood. Some \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m )\n\u001b[1;32m--> 221\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[43mdispatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mload(uri, frame_offset, num_frames, normalize, channels_first, \u001b[38;5;28mformat\u001b[39m, buffer_size)\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\torch4\\lib\\site-packages\\torchaudio\\_backend\\utils.py:117\u001b[0m, in \u001b[0;36mget_load_func.<locals>.dispatcher\u001b[1;34m(uri, format, backend_name)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcan_decode(uri, \u001b[38;5;28mformat\u001b[39m):\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m backend\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find appropriate backend to handle uri \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and format \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mformat\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Couldn't find appropriate backend to handle uri well.wav and format None."
     ]
    }
   ],
   "source": [
    "torchaudio.set_audio_backend('sox_io')\n",
    "waveform,sample_rate = torchaudio.load('well.wav')\n",
    "print(waveform.shape)\n",
    "print(sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
