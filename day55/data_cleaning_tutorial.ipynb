{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§¹ Data Cleaning with Pandas - Complete Tutorial\n",
    "\n",
    "This tutorial will teach you how to clean **dirty data** using **pandas**. We'll work with a real-world-like messy dataset and fix common data quality issues.\n",
    "\n",
    "## What You'll Learn:\n",
    "1. Identifying data quality issues\n",
    "2. Handling missing values\n",
    "3. Removing duplicates\n",
    "4. Fixing inconsistent formatting (casing, whitespace)\n",
    "5. Handling outliers and invalid values\n",
    "6. Standardizing date formats\n",
    "7. Data type conversions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (50, 10)\n",
      "\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>department</th>\n",
       "      <th>salary</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>phone_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>Smith</td>\n",
       "      <td>john.smith@company.com</td>\n",
       "      <td>Sales</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>28</td>\n",
       "      <td>New York</td>\n",
       "      <td>555-1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Doe</td>\n",
       "      <td>jane.doe@company.com</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>32</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>555-5678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MICHAEL</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>michael.johnson@company.com</td>\n",
       "      <td>IT</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>2018-07-10</td>\n",
       "      <td>35</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>555-9012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>emily</td>\n",
       "      <td>Brown</td>\n",
       "      <td>emily.brown@company.com</td>\n",
       "      <td>HR</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>2021-05-18</td>\n",
       "      <td>26</td>\n",
       "      <td>Houston</td>\n",
       "      <td>555-3456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>David</td>\n",
       "      <td>Williams</td>\n",
       "      <td>david.williams@company.com</td>\n",
       "      <td>Sales</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>30</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>555-7890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finance</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>34</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>(555) 2345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>James</td>\n",
       "      <td>Davis</td>\n",
       "      <td>james.davis@company.com</td>\n",
       "      <td>IT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-02-14</td>\n",
       "      <td>38</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>555.6789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>jennifer.garcia@company.com</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>29</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>555-0123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Robert</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>robert.martinez@company.com</td>\n",
       "      <td>Sales</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>2019-09-12</td>\n",
       "      <td>31</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>555-4567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Lisa</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>lisa.anderson@company.com</td>\n",
       "      <td>HR</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>27</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>5558901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id first_name last_name                        email department  \\\n",
       "0            1       John     Smith       john.smith@company.com      Sales   \n",
       "1            2       Jane       Doe         jane.doe@company.com  Marketing   \n",
       "2            3    MICHAEL   Johnson  michael.johnson@company.com         IT   \n",
       "3            4      emily     Brown      emily.brown@company.com         HR   \n",
       "4            5      David  Williams   david.williams@company.com      Sales   \n",
       "5            6      Sarah    Miller                          NaN    Finance   \n",
       "6            7      James     Davis      james.davis@company.com         IT   \n",
       "7            8   Jennifer    Garcia  jennifer.garcia@company.com  Marketing   \n",
       "8            9     Robert  Martinez  robert.martinez@company.com      Sales   \n",
       "9           10       Lisa  Anderson    lisa.anderson@company.com         HR   \n",
       "\n",
       "    salary   hire_date  age          city phone_number  \n",
       "0  55000.0  2020-01-15   28      New York     555-1234  \n",
       "1  62000.0  2019-03-22   32   Los Angeles     555-5678  \n",
       "2  75000.0  2018-07-10   35       Chicago     555-9012  \n",
       "3  48000.0  2021-05-18   26       Houston     555-3456  \n",
       "4  58000.0  2020-08-25   30       Phoenix     555-7890  \n",
       "5  67000.0  2019-11-03   34  Philadelphia   (555) 2345  \n",
       "6      NaN  2017-02-14   38   San Antonio     555.6789  \n",
       "7  54000.0  2020-04-30   29     San Diego     555-0123  \n",
       "8  56000.0  2019-09-12   31        Dallas     555-4567  \n",
       "9  51000.0  2021-01-20   27      San Jose      5558901  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dirty dataset\n",
    "df = pd.read_csv('dirty_employees.csv')\n",
    "\n",
    "# Display basic info\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Explore the Data (Find the Problems!)\n",
    "\n",
    "Before cleaning, we need to understand what's wrong with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      "employee_id       int64\n",
      "first_name       object\n",
      "last_name        object\n",
      "email            object\n",
      "department       object\n",
      "salary          float64\n",
      "hire_date        object\n",
      "age               int64\n",
      "city             object\n",
      "phone_number     object\n",
      "dtype: object\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Count:\n",
      "employee_id     0\n",
      "first_name      1\n",
      "last_name       0\n",
      "email           1\n",
      "department      0\n",
      "salary          3\n",
      "hire_date       0\n",
      "age             0\n",
      "city            0\n",
      "phone_number    0\n",
      "dtype: int64\n",
      "\n",
      "Total Missing Values: 5\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values Count:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nTotal Missing Values:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"Number of duplicate rows:\", df.duplicated().sum())\n",
    "print(\"\\nDuplicate rows:\")\n",
    "df[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in categorical columns\n",
    "print(\"Unique departments (notice the inconsistencies):\")\n",
    "print(df['department'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at salary statistics (notice outliers)\n",
    "print(\"Salary Statistics:\")\n",
    "print(df['salary'].describe())\n",
    "print(\"\\nUnique salary values that look suspicious:\")\n",
    "print(df['salary'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“‹ Problems We Found:\n",
    "\n",
    "1. **Missing values**: Empty cells, 'NULL', 'N/A' in various columns\n",
    "2. **Duplicate rows**: Row 1 and 11 are identical\n",
    "3. **Inconsistent casing**: 'Sales', 'sales', 'MICHAEL', 'emily'\n",
    "4. **Whitespace issues**: ' Sales ', '   HR   ', ' Fort Worth'\n",
    "5. **Invalid values**: Negative salary (-5000), negative age (-25)\n",
    "6. **Outliers**: Salary of 650000 (typo), salary of 150 (too low)\n",
    "7. **Inconsistent date formats**: '2020-01-15' vs '15-03-2021'\n",
    "8. **Inconsistent phone formats**: '555-1234', '(555) 2345', '555.6789', '5558901'\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Handle Missing Values\n",
    "\n",
    "### 3.1 Replace text placeholders with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy to preserve original\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Replace common missing value representations with NaN\n",
    "df_clean = df_clean.replace(['NULL', 'N/A', 'n/a', 'NA', '', ' '], np.nan)\n",
    "\n",
    "print(\"Missing values after replacement:\")\n",
    "print(df_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Handle Missing Values - Different Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRATEGY 1: Drop rows with missing values (use when you have lots of data)\n",
    "# df_clean = df_clean.dropna()\n",
    "\n",
    "# STRATEGY 2: Fill with specific values\n",
    "# For salary: fill with median (more robust than mean for outliers)\n",
    "salary_median = df_clean['salary'].median()\n",
    "print(f\"Median salary: {salary_median}\")\n",
    "\n",
    "df_clean['salary'] = df_clean['salary'].fillna(salary_median)\n",
    "\n",
    "# For first_name: fill with 'Unknown'\n",
    "df_clean['first_name'] = df_clean['first_name'].fillna('Unknown')\n",
    "\n",
    "# For email: we could construct it from name, or leave as 'no.email@company.com'\n",
    "df_clean['email'] = df_clean['email'].fillna('no.email@company.com')\n",
    "\n",
    "print(\"\\nMissing values after filling:\")\n",
    "print(df_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Rows before removing duplicates: {len(df_clean)}\")\n",
    "\n",
    "# Remove duplicate rows (keep first occurrence)\n",
    "df_clean = df_clean.drop_duplicates(keep='first')\n",
    "\n",
    "print(f\"Rows after removing duplicates: {len(df_clean)}\")\n",
    "\n",
    "# You can also check for duplicates based on specific columns\n",
    "# df_clean = df_clean.drop_duplicates(subset=['email'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Fix Inconsistent Casing and Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix department: strip whitespace and title case\n",
    "df_clean['department'] = df_clean['department'].str.strip().str.title()\n",
    "\n",
    "print(\"Unique departments after cleaning:\")\n",
    "print(df_clean['department'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix names: strip whitespace and title case\n",
    "df_clean['first_name'] = df_clean['first_name'].str.strip().str.title()\n",
    "df_clean['last_name'] = df_clean['last_name'].str.strip().str.title()\n",
    "\n",
    "# Fix city: strip whitespace and title case\n",
    "df_clean['city'] = df_clean['city'].str.strip().str.title()\n",
    "\n",
    "# Fix email: lowercase\n",
    "df_clean['email'] = df_clean['email'].str.strip().str.lower()\n",
    "\n",
    "print(\"Sample of cleaned names:\")\n",
    "df_clean[['first_name', 'last_name', 'email', 'city']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Handle Invalid Values and Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows with invalid salary (negative values)\n",
    "print(\"Rows with negative salary:\")\n",
    "print(df_clean[df_clean['salary'] < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert salary to numeric first (in case there are strings)\n",
    "df_clean['salary'] = pd.to_numeric(df_clean['salary'], errors='coerce')\n",
    "\n",
    "# Fix negative values: replace with median\n",
    "salary_median = df_clean[df_clean['salary'] > 0]['salary'].median()\n",
    "df_clean.loc[df_clean['salary'] <= 0, 'salary'] = salary_median\n",
    "\n",
    "print(f\"After fixing negative salaries - Min: {df_clean['salary'].min()}, Max: {df_clean['salary'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers using IQR method\n",
    "Q1 = df_clean['salary'].quantile(0.25)\n",
    "Q3 = df_clean['salary'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"IQR: {IQR}\")\n",
    "print(f\"Lower bound: {lower_bound}\")\n",
    "print(f\"Upper bound: {upper_bound}\")\n",
    "\n",
    "# Find outliers\n",
    "outliers = df_clean[(df_clean['salary'] < lower_bound) | (df_clean['salary'] > upper_bound)]\n",
    "print(f\"\\nNumber of outliers: {len(outliers)}\")\n",
    "print(outliers[['employee_id', 'first_name', 'salary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Cap outliers at bounds\n",
    "df_clean['salary'] = df_clean['salary'].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "# Option 2: Replace with median (uncomment to use)\n",
    "# df_clean.loc[(df_clean['salary'] < lower_bound) | (df_clean['salary'] > upper_bound), 'salary'] = salary_median\n",
    "\n",
    "print(f\"After handling outliers - Min: {df_clean['salary'].min()}, Max: {df_clean['salary'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix negative age values\n",
    "df_clean['age'] = pd.to_numeric(df_clean['age'], errors='coerce')\n",
    "df_clean.loc[df_clean['age'] < 0, 'age'] = df_clean['age'].abs()  # Take absolute value\n",
    "\n",
    "print(f\"Age range: {df_clean['age'].min()} to {df_clean['age'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Standardize Date Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current date values\n",
    "print(\"Sample hire_date values:\")\n",
    "print(df_clean['hire_date'].head(20).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime with multiple format inference\n",
    "# The 'dayfirst' parameter helps with ambiguous dates\n",
    "df_clean['hire_date'] = pd.to_datetime(df_clean['hire_date'], dayfirst=False, errors='coerce')\n",
    "\n",
    "# For dates that might be in different format (DD-MM-YYYY)\n",
    "# We need a custom function to handle mixed formats\n",
    "def parse_mixed_dates(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        # Try standard format first (YYYY-MM-DD)\n",
    "        return pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "    except:\n",
    "        try:\n",
    "            # Try DD-MM-YYYY format\n",
    "            return pd.to_datetime(date_str, format='%d-%m-%Y')\n",
    "        except:\n",
    "            return pd.NaT\n",
    "\n",
    "# Reload and apply custom parsing\n",
    "df_temp = pd.read_csv('dirty_employees.csv')\n",
    "df_clean['hire_date'] = df_temp['hire_date'].apply(parse_mixed_dates)\n",
    "\n",
    "print(\"Hire dates after conversion:\")\n",
    "print(df_clean['hire_date'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: Standardize Phone Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current phone formats\n",
    "print(\"Current phone number formats:\")\n",
    "print(df_clean['phone_number'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def standardize_phone(phone):\n",
    "    if pd.isna(phone):\n",
    "        return np.nan\n",
    "    # Remove all non-numeric characters\n",
    "    digits = re.sub(r'\\D', '', str(phone))\n",
    "    # Format as XXX-XXXX (assuming 7 digits)\n",
    "    if len(digits) == 7:\n",
    "        return f\"{digits[:3]}-{digits[3:]}\"\n",
    "    # Format as (XXX) XXX-XXXX for 10 digits\n",
    "    elif len(digits) == 10:\n",
    "        return f\"({digits[:3]}) {digits[3:6]}-{digits[6:]}\"\n",
    "    return digits\n",
    "\n",
    "df_clean['phone_number'] = df_clean['phone_number'].apply(standardize_phone)\n",
    "\n",
    "print(\"Standardized phone numbers:\")\n",
    "print(df_clean['phone_number'].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 9: Reset Index and Final Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index after removing rows\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "\n",
    "# Final overview\n",
    "print(\"=\" * 50)\n",
    "print(\"FINAL CLEANED DATASET SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nShape: {df_clean.shape}\")\n",
    "print(f\"\\nMissing values:\\n{df_clean.isnull().sum()}\")\n",
    "print(f\"\\nDuplicates: {df_clean.duplicated().sum()}\")\n",
    "print(f\"\\nData types:\\n{df_clean.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the cleaned data\n",
    "df_clean.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify salary statistics are reasonable now\n",
    "print(\"Cleaned Salary Statistics:\")\n",
    "print(df_clean['salary'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 10: Save the Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a new CSV file\n",
    "df_clean.to_csv('cleaned_employees.csv', index=False)\n",
    "print(\"âœ… Cleaned data saved to 'cleaned_employees.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ“š Quick Reference Cheatsheet\n",
    "\n",
    "## Common Pandas Cleaning Functions\n",
    "\n",
    "| Issue | Solution |\n",
    "|-------|----------|\n",
    "| Missing values | `df.isnull().sum()`, `df.fillna(value)`, `df.dropna()` |\n",
    "| Duplicates | `df.duplicated()`, `df.drop_duplicates()` |\n",
    "| Whitespace | `df['col'].str.strip()` |\n",
    "| Case issues | `df['col'].str.lower()`, `.upper()`, `.title()` |\n",
    "| Replace values | `df.replace(old, new)` |\n",
    "| Convert types | `df['col'].astype(type)`, `pd.to_numeric()`, `pd.to_datetime()` |\n",
    "| Outliers | `df['col'].clip(lower, upper)` |\n",
    "| Filter data | `df[df['col'] > value]` |\n",
    "| Apply function | `df['col'].apply(func)` |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Practice Exercises\n",
    "\n",
    "Try these on your own:\n",
    "\n",
    "1. Create a new column `full_name` by combining first_name and last_name\n",
    "2. Calculate the average salary by department\n",
    "3. Find employees hired before 2019\n",
    "4. Create age groups (20-25, 26-30, 31-35, 36-40)\n",
    "5. Find the department with the highest average salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice Exercise 1: Create full_name\n",
    "df_clean['full_name'] = df_clean['first_name'] + ' ' + df_clean['last_name']\n",
    "df_clean['full_name'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice Exercise 2: Average salary by department\n",
    "df_clean.groupby('department')['salary'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice Exercise 3: Employees hired before 2019\n",
    "df_clean[df_clean['hire_date'] < '2019-01-01'][['full_name', 'department', 'hire_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice Exercise 4: Create age groups\n",
    "bins = [20, 25, 30, 35, 40, 100]\n",
    "labels = ['20-25', '26-30', '31-35', '36-40', '40+']\n",
    "df_clean['age_group'] = pd.cut(df_clean['age'], bins=bins, labels=labels)\n",
    "df_clean['age_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice Exercise 5: Department with highest average salary\n",
    "print(\"Department with highest average salary:\")\n",
    "print(df_clean.groupby('department')['salary'].mean().idxmax())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
