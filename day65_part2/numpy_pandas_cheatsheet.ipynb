{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä NumPy & Pandas Cheat Sheet for Social Media Data Analysis\n",
        "\n",
        "**Dataset Columns:** `platform`, `post_type`, `post_length`, `views`, `likes`, `comments`, `shares`, `engagement_rate`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üîß Setup & Sample Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Sample Social Media Data\n",
        "data = {\n",
        "    'platform': ['Instagram', 'Twitter', 'Facebook', 'Instagram', 'TikTok', 'Twitter', 'Facebook', 'TikTok'],\n",
        "    'post_type': ['image', 'text', 'video', 'reel', 'video', 'image', 'text', 'video'],\n",
        "    'post_length': [150, 280, 500, 30, 60, 200, 1000, 45],\n",
        "    'views': [5000, 1200, 8000, 25000, 50000, 800, 3000, 75000],\n",
        "    'likes': [450, 50, 600, 3000, 8000, 30, 150, 12000],\n",
        "    'comments': [45, 10, 80, 200, 500, 5, 20, 800],\n",
        "    'shares': [20, 5, 100, 300, 1000, 2, 15, 1500],\n",
        "    'engagement_rate': [10.3, 5.4, 9.75, 14.0, 19.0, 4.6, 6.2, 19.1]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# üî¢ NUMPY CHEAT SHEET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Converting DataFrame Columns to NumPy Arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert columns to NumPy arrays\n",
        "views_arr = df['views'].to_numpy()\n",
        "likes_arr = df['likes'].to_numpy()\n",
        "comments_arr = df['comments'].to_numpy()\n",
        "shares_arr = df['shares'].to_numpy()\n",
        "engagement_arr = df['engagement_rate'].to_numpy()\n",
        "\n",
        "print(\"Views Array:\", views_arr)\n",
        "print(\"Type:\", type(views_arr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Basic Statistical Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mean, Median, Standard Deviation\n",
        "print(\"=== VIEWS STATISTICS ===\")\n",
        "print(f\"Mean Views: {np.mean(views_arr):,.2f}\")\n",
        "print(f\"Median Views: {np.median(views_arr):,.2f}\")\n",
        "print(f\"Std Dev Views: {np.std(views_arr):,.2f}\")\n",
        "print(f\"Variance: {np.var(views_arr):,.2f}\")\n",
        "\n",
        "print(\"\\n=== MIN/MAX ===\")\n",
        "print(f\"Min Views: {np.min(views_arr):,}\")\n",
        "print(f\"Max Views: {np.max(views_arr):,}\")\n",
        "print(f\"Range: {np.ptp(views_arr):,}\")  # Peak to Peak (max - min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Percentiles & Quantiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Percentiles\n",
        "print(\"25th Percentile (Q1):\", np.percentile(views_arr, 25))\n",
        "print(\"50th Percentile (Q2/Median):\", np.percentile(views_arr, 50))\n",
        "print(\"75th Percentile (Q3):\", np.percentile(views_arr, 75))\n",
        "print(\"90th Percentile:\", np.percentile(views_arr, 90))\n",
        "\n",
        "# Multiple percentiles at once\n",
        "percentiles = np.percentile(engagement_arr, [10, 25, 50, 75, 90])\n",
        "print(\"\\nEngagement Rate Percentiles [10,25,50,75,90]:\", percentiles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Correlation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation between views and likes\n",
        "correlation = np.corrcoef(views_arr, likes_arr)\n",
        "print(\"Correlation Matrix (Views vs Likes):\")\n",
        "print(correlation)\n",
        "print(f\"\\nCorrelation Coefficient: {correlation[0,1]:.4f}\")\n",
        "\n",
        "# Interpretation:\n",
        "# 1.0 = perfect positive correlation\n",
        "# 0 = no correlation\n",
        "# -1.0 = perfect negative correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Array Operations & Broadcasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate total engagement (likes + comments + shares)\n",
        "total_engagement = likes_arr + comments_arr + shares_arr\n",
        "print(\"Total Engagement per post:\", total_engagement)\n",
        "\n",
        "# Calculate engagement rate manually\n",
        "manual_engagement_rate = (total_engagement / views_arr) * 100\n",
        "print(\"\\nManual Engagement Rate %:\", np.round(manual_engagement_rate, 2))\n",
        "\n",
        "# Normalize views (0-1 scale)\n",
        "normalized_views = (views_arr - np.min(views_arr)) / (np.max(views_arr) - np.min(views_arr))\n",
        "print(\"\\nNormalized Views (0-1):\", np.round(normalized_views, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Conditional Filtering with NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter: Posts with views > 10000\n",
        "high_views = views_arr[views_arr > 10000]\n",
        "print(\"High Views (>10K):\", high_views)\n",
        "\n",
        "# Filter: Posts with engagement > 10%\n",
        "high_engagement = engagement_arr[engagement_arr > 10]\n",
        "print(\"High Engagement (>10%):\", high_engagement)\n",
        "\n",
        "# Count posts meeting criteria\n",
        "viral_count = np.sum(views_arr > 20000)\n",
        "print(f\"\\nNumber of viral posts (>20K views): {viral_count}\")\n",
        "\n",
        "# Get indices of top performers\n",
        "top_indices = np.where(engagement_arr > 15)[0]\n",
        "print(\"Indices of high engagement posts:\", top_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Sorting & Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort views\n",
        "sorted_views = np.sort(views_arr)\n",
        "print(\"Sorted Views (ascending):\", sorted_views)\n",
        "\n",
        "# Sort descending\n",
        "sorted_desc = np.sort(views_arr)[::-1]\n",
        "print(\"Sorted Views (descending):\", sorted_desc)\n",
        "\n",
        "# Get indices that would sort the array\n",
        "sort_indices = np.argsort(views_arr)[::-1]  # Descending order indices\n",
        "print(\"\\nTop 3 post indices by views:\", sort_indices[:3])\n",
        "\n",
        "# Index of max/min\n",
        "print(f\"Index of max views: {np.argmax(views_arr)}\")\n",
        "print(f\"Index of min views: {np.argmin(views_arr)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Unique Values & Counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert categorical to array\n",
        "platforms = df['platform'].to_numpy()\n",
        "\n",
        "# Get unique values\n",
        "unique_platforms = np.unique(platforms)\n",
        "print(\"Unique Platforms:\", unique_platforms)\n",
        "\n",
        "# Get unique values with counts\n",
        "unique, counts = np.unique(platforms, return_counts=True)\n",
        "print(\"\\nPlatform Distribution:\")\n",
        "for platform, count in zip(unique, counts):\n",
        "    print(f\"  {platform}: {count} posts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Mathematical Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sum, Cumulative Sum, Product\n",
        "print(\"Total Views:\", np.sum(views_arr))\n",
        "print(\"Total Likes:\", np.sum(likes_arr))\n",
        "print(\"\\nCumulative Views:\", np.cumsum(views_arr))\n",
        "\n",
        "# Log transformation (useful for skewed data)\n",
        "log_views = np.log10(views_arr)\n",
        "print(\"\\nLog10 of Views:\", np.round(log_views, 2))\n",
        "\n",
        "# Square root transformation\n",
        "sqrt_views = np.sqrt(views_arr)\n",
        "print(\"Square Root of Views:\", np.round(sqrt_views, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Creating Bins/Categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Digitize: Assign views to bins\n",
        "bins = [0, 1000, 5000, 20000, 100000]\n",
        "labels = ['Low', 'Medium', 'High', 'Viral']\n",
        "\n",
        "bin_indices = np.digitize(views_arr, bins)\n",
        "print(\"Bin Indices:\", bin_indices)\n",
        "\n",
        "# Histogram\n",
        "hist, bin_edges = np.histogram(views_arr, bins=4)\n",
        "print(\"\\nHistogram counts:\", hist)\n",
        "print(\"Bin edges:\", bin_edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# üêº PANDAS CHEAT SHEET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Basic DataFrame Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic Info\n",
        "print(\"=== DATAFRAME INFO ===\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")\n",
        "print(f\"\\nData Types:\\n{df.dtypes}\")\n",
        "\n",
        "# Preview data\n",
        "print(\"\\n=== HEAD & TAIL ===\")\n",
        "display(df.head(3))\n",
        "display(df.tail(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Descriptive Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Full statistical summary\n",
        "print(\"=== DESCRIBE (Numeric Columns) ===\")\n",
        "display(df.describe())\n",
        "\n",
        "# Include categorical columns\n",
        "print(\"\\n=== DESCRIBE (All Columns) ===\")\n",
        "display(df.describe(include='all'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Value Counts & Unique Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Value counts for categorical\n",
        "print(\"=== PLATFORM DISTRIBUTION ===\")\n",
        "print(df['platform'].value_counts())\n",
        "\n",
        "print(\"\\n=== POST TYPE DISTRIBUTION ===\")\n",
        "print(df['post_type'].value_counts())\n",
        "\n",
        "# Normalized (percentage)\n",
        "print(\"\\n=== PLATFORM % ===\")\n",
        "print(df['platform'].value_counts(normalize=True).mul(100).round(2))\n",
        "\n",
        "# Number of unique values\n",
        "print(f\"\\nUnique platforms: {df['platform'].nunique()}\")\n",
        "print(f\"Unique post types: {df['post_type'].nunique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Filtering Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter by single condition\n",
        "high_views_df = df[df['views'] > 10000]\n",
        "print(\"Posts with >10K views:\")\n",
        "display(high_views_df)\n",
        "\n",
        "# Filter by multiple conditions (AND)\n",
        "viral_engaged = df[(df['views'] > 10000) & (df['engagement_rate'] > 10)]\n",
        "print(\"\\nViral AND High Engagement:\")\n",
        "display(viral_engaged)\n",
        "\n",
        "# Filter by multiple conditions (OR)\n",
        "instagram_or_tiktok = df[(df['platform'] == 'Instagram') | (df['platform'] == 'TikTok')]\n",
        "print(\"\\nInstagram OR TikTok posts:\")\n",
        "display(instagram_or_tiktok)\n",
        "\n",
        "# Filter using isin()\n",
        "selected_platforms = df[df['platform'].isin(['Instagram', 'TikTok'])]\n",
        "print(\"\\nUsing isin() - Same result:\")\n",
        "display(selected_platforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. GroupBy Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group by platform - basic aggregation\n",
        "print(\"=== AVERAGE VIEWS BY PLATFORM ===\")\n",
        "print(df.groupby('platform')['views'].mean().round(0))\n",
        "\n",
        "# Multiple aggregations\n",
        "print(\"\\n=== MULTIPLE STATS BY PLATFORM ===\")\n",
        "platform_stats = df.groupby('platform').agg({\n",
        "    'views': ['mean', 'sum', 'count'],\n",
        "    'likes': ['mean', 'sum'],\n",
        "    'engagement_rate': 'mean'\n",
        "}).round(2)\n",
        "display(platform_stats)\n",
        "\n",
        "# Group by multiple columns\n",
        "print(\"\\n=== GROUP BY PLATFORM & POST TYPE ===\")\n",
        "multi_group = df.groupby(['platform', 'post_type'])['engagement_rate'].mean().round(2)\n",
        "print(multi_group)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Sorting & Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort by single column\n",
        "sorted_by_views = df.sort_values('views', ascending=False)\n",
        "print(\"=== SORTED BY VIEWS (DESC) ===\")\n",
        "display(sorted_by_views)\n",
        "\n",
        "# Sort by multiple columns\n",
        "sorted_multi = df.sort_values(['platform', 'views'], ascending=[True, False])\n",
        "print(\"\\n=== SORTED BY PLATFORM, THEN VIEWS ===\")\n",
        "display(sorted_multi)\n",
        "\n",
        "# Top N\n",
        "print(\"\\n=== TOP 3 BY ENGAGEMENT ===\")\n",
        "display(df.nlargest(3, 'engagement_rate'))\n",
        "\n",
        "# Bottom N\n",
        "print(\"\\n=== BOTTOM 3 BY VIEWS ===\")\n",
        "display(df.nsmallest(3, 'views'))\n",
        "\n",
        "# Add rank column\n",
        "df['views_rank'] = df['views'].rank(ascending=False).astype(int)\n",
        "print(\"\\n=== WITH RANK COLUMN ===\")\n",
        "display(df[['platform', 'post_type', 'views', 'views_rank']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Creating New Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple calculation\n",
        "df['total_interactions'] = df['likes'] + df['comments'] + df['shares']\n",
        "\n",
        "# Calculated column\n",
        "df['likes_per_view'] = (df['likes'] / df['views'] * 100).round(2)\n",
        "\n",
        "# Conditional column using np.where\n",
        "df['performance'] = np.where(df['engagement_rate'] > 10, 'High', 'Low')\n",
        "\n",
        "# Multiple conditions using np.select\n",
        "conditions = [\n",
        "    df['views'] >= 50000,\n",
        "    df['views'] >= 10000,\n",
        "    df['views'] >= 5000\n",
        "]\n",
        "choices = ['Viral', 'Popular', 'Growing']\n",
        "df['view_category'] = np.select(conditions, choices, default='Starting')\n",
        "\n",
        "print(\"=== NEW COLUMNS ADDED ===\")\n",
        "display(df[['platform', 'views', 'total_interactions', 'likes_per_view', 'performance', 'view_category']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Binning / Categorizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cut: Equal-width bins\n",
        "df['engagement_bin'] = pd.cut(df['engagement_rate'], \n",
        "                               bins=[0, 5, 10, 15, 20],\n",
        "                               labels=['Poor', 'Average', 'Good', 'Excellent'])\n",
        "\n",
        "# Qcut: Equal-frequency bins (quartiles)\n",
        "df['views_quartile'] = pd.qcut(df['views'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
        "\n",
        "print(\"=== BINNED DATA ===\")\n",
        "display(df[['platform', 'views', 'views_quartile', 'engagement_rate', 'engagement_bin']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Pivot Tables & Cross Tabulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple Pivot Table\n",
        "print(\"=== PIVOT: AVERAGE ENGAGEMENT BY PLATFORM & POST TYPE ===\")\n",
        "pivot = df.pivot_table(\n",
        "    values='engagement_rate',\n",
        "    index='platform',\n",
        "    columns='post_type',\n",
        "    aggfunc='mean'\n",
        ").round(2)\n",
        "display(pivot)\n",
        "\n",
        "# Cross tabulation (frequency table)\n",
        "print(\"\\n=== CROSSTAB: COUNT BY PLATFORM & PERFORMANCE ===\")\n",
        "crosstab = pd.crosstab(df['platform'], df['performance'])\n",
        "display(crosstab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select numeric columns only\n",
        "numeric_cols = df.select_dtypes(include=[np.number])\n",
        "\n",
        "# Correlation matrix\n",
        "print(\"=== CORRELATION MATRIX ===\")\n",
        "correlation_matrix = numeric_cols.corr().round(3)\n",
        "display(correlation_matrix)\n",
        "\n",
        "# Specific correlation\n",
        "print(f\"\\nViews-Likes Correlation: {df['views'].corr(df['likes']):.4f}\")\n",
        "print(f\"Views-Engagement Correlation: {df['views'].corr(df['engagement_rate']):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Apply & Lambda Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply to single column\n",
        "df['views_in_k'] = df['views'].apply(lambda x: f\"{x/1000:.1f}K\")\n",
        "\n",
        "# Apply to create categorical\n",
        "def categorize_length(length):\n",
        "    if length < 100:\n",
        "        return 'Short'\n",
        "    elif length < 500:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'Long'\n",
        "\n",
        "df['content_length_category'] = df['post_length'].apply(categorize_length)\n",
        "\n",
        "# Apply across row (axis=1)\n",
        "df['summary'] = df.apply(\n",
        "    lambda row: f\"{row['platform']}-{row['post_type']}: {row['engagement_rate']}%\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(\"=== APPLIED TRANSFORMATIONS ===\")\n",
        "display(df[['platform', 'views', 'views_in_k', 'post_length', 'content_length_category', 'summary']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Aggregation Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive summary by platform\n",
        "summary = df.groupby('platform').agg(\n",
        "    total_posts=('platform', 'count'),\n",
        "    total_views=('views', 'sum'),\n",
        "    avg_views=('views', 'mean'),\n",
        "    total_likes=('likes', 'sum'),\n",
        "    avg_engagement=('engagement_rate', 'mean'),\n",
        "    max_engagement=('engagement_rate', 'max'),\n",
        "    total_interactions=('total_interactions', 'sum')\n",
        ").round(2)\n",
        "\n",
        "print(\"=== PLATFORM PERFORMANCE SUMMARY ===\")\n",
        "display(summary)\n",
        "\n",
        "# Best performing platform\n",
        "best_platform = summary['avg_engagement'].idxmax()\n",
        "print(f\"\\nüèÜ Best Platform by Avg Engagement: {best_platform}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# üìã QUICK REFERENCE\n",
        "\n",
        "## NumPy Quick Reference\n",
        "| Operation | Code |\n",
        "|-----------|------|\n",
        "| Mean | `np.mean(arr)` |\n",
        "| Median | `np.median(arr)` |\n",
        "| Std Dev | `np.std(arr)` |\n",
        "| Min/Max | `np.min(arr)`, `np.max(arr)` |\n",
        "| Percentile | `np.percentile(arr, 75)` |\n",
        "| Correlation | `np.corrcoef(arr1, arr2)` |\n",
        "| Sort | `np.sort(arr)` |\n",
        "| Unique | `np.unique(arr)` |\n",
        "| Filter | `arr[arr > value]` |\n",
        "| Sum | `np.sum(arr)` |\n",
        "\n",
        "## Pandas Quick Reference\n",
        "| Operation | Code |\n",
        "|-----------|------|\n",
        "| Filter rows | `df[df['col'] > value]` |\n",
        "| Group by | `df.groupby('col').mean()` |\n",
        "| Value counts | `df['col'].value_counts()` |\n",
        "| Sort | `df.sort_values('col')` |\n",
        "| Top N | `df.nlargest(n, 'col')` |\n",
        "| New column | `df['new'] = df['a'] + df['b']` |\n",
        "| Pivot | `df.pivot_table(...)` |\n",
        "| Apply | `df['col'].apply(func)` |\n",
        "| Describe | `df.describe()` |\n",
        "| Correlation | `df.corr()` |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# ‚öñÔ∏è PROS AND CONS\n",
        "\n",
        "## NumPy\n",
        "| Pros ‚úÖ | Cons ‚ùå |\n",
        "|---------|--------|\n",
        "| Very fast for numerical computations | No built-in support for labeled data |\n",
        "| Memory efficient | Harder to work with mixed data types |\n",
        "| Great for mathematical operations | No built-in groupby functionality |\n",
        "| Foundation for other libraries | Limited data manipulation features |\n",
        "| Broadcasting is powerful | Steeper learning curve for indexing |\n",
        "\n",
        "## Pandas\n",
        "| Pros ‚úÖ | Cons ‚ùå |\n",
        "|---------|--------|\n",
        "| Easy to work with tabular data | Slower than NumPy for large arrays |\n",
        "| Powerful groupby & aggregation | Higher memory usage |\n",
        "| Great for data cleaning | Can be confusing with index behavior |\n",
        "| Handles missing data well | Multiple ways to do same thing |\n",
        "| Built on NumPy (best of both) | Performance issues with very large data |\n",
        "\n",
        "## When to Use Which?\n",
        "- **NumPy**: Pure numerical operations, matrix math, image processing, when speed is critical\n",
        "- **Pandas**: Working with CSV/Excel, data cleaning, groupby analysis, exploratory data analysis"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
